{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f074d6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset_path = 'Audio_Speech_Actors_01-24'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd09eab",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def build_logmel_feature(audio_file, duration=3, sr=22050):\n",
    "\n",
    "    signal, _ = librosa.load(audio_file, duration=duration)\n",
    "\n",
    "    # Remove silence\n",
    "    signal, _ = librosa.effects.trim(signal)\n",
    "\n",
    "    # Ensure equal length\n",
    "    target_len = duration * sr\n",
    "    if len(signal) < target_len:\n",
    "        signal = np.pad(signal, (0, target_len - len(signal)))\n",
    "    else:\n",
    "        signal = signal[:target_len]\n",
    "\n",
    "    mel = librosa.feature.melspectrogram(y=signal, sr=sr, n_mels=128)\n",
    "    logmel = librosa.power_to_db(mel, ref=np.max)\n",
    "\n",
    "    # Normalize\n",
    "    logmel = (logmel - np.mean(logmel)) / (np.std(logmel) + 1e-6)\n",
    "\n",
    "    return logmel[..., np.newaxis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e9b9ba",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "features_list = []\n",
    "label_list = []\n",
    "\n",
    "for root_dir, folder_names, file_names in os.walk(dataset_path):\n",
    "\n",
    "    for wav_file in file_names:\n",
    "\n",
    "        if wav_file.endswith('.wav'):\n",
    "\n",
    "            name_parts = wav_file.split('-')\n",
    "\n",
    "            if len(name_parts) > 2:\n",
    "\n",
    "                emotion_id = int(name_parts[2]) - 1\n",
    "                absolute_path = os.path.join(root_dir, wav_file)\n",
    "\n",
    "                features_list.append(build_logmel_feature(absolute_path))\n",
    "                label_list.append(emotion_id)\n",
    "\n",
    "features_array = np.array(features_list)\n",
    "labels_array = np.array(label_list)\n",
    "\n",
    "print(\"Dataset Loaded:\", features_array.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cc6cf8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_x, temp_x, train_y, temp_y = train_test_split(\n",
    "    features_array,\n",
    "    labels_array,\n",
    "    test_size=0.2,\n",
    "    stratify=labels_array,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "val_x, test_x, val_y, test_y = train_test_split(\n",
    "    temp_x,\n",
    "    temp_y,\n",
    "    test_size=0.5,\n",
    "    stratify=temp_y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", train_x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a108ba",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "\n",
    "    layers.Input(shape=train_x.shape[1:]),\n",
    "\n",
    "    layers.Conv2D(32,(3,3),activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Conv2D(64,(3,3),activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Conv2D(128,(3,3),activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "\n",
    "    layers.Dropout(0.4),\n",
    "\n",
    "    layers.Dense(64,activation='relu'),\n",
    "    layers.Dense(8,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0005b372",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_x,\n",
    "    train_y,\n",
    "    epochs=35,\n",
    "    batch_size=32,\n",
    "    validation_data=(val_x,val_y)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6101f1a9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model.save('ser_model.keras')\n",
    "print(\"Model trained and saved as ser_model.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d33fb29",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_x, test_y)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b29e464",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
